==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Model                                    [128, 42]                 --
├─Sequential: 1-1                        [128, 64, 64, 64]         --
│    └─Conv2d: 2-1                       [128, 64, 64, 64]         1,792
│    └─BatchNorm2d: 2-2                  [128, 64, 64, 64]         128
│    └─ReLU: 2-3                         [128, 64, 64, 64]         --
├─Sequential: 1-2                        [128, 128, 32, 32]        --
│    └─Conv2d: 2-4                       [128, 128, 64, 64]        73,856
│    └─BatchNorm2d: 2-5                  [128, 128, 64, 64]        256
│    └─ReLU: 2-6                         [128, 128, 64, 64]        --
│    └─MaxPool2d: 2-7                    [128, 128, 32, 32]        --
├─Sequential: 1-3                        [128, 128, 32, 32]        --
│    └─Sequential: 2-8                   [128, 128, 32, 32]        --
│    │    └─Conv2d: 3-1                  [128, 128, 32, 32]        147,584
│    │    └─BatchNorm2d: 3-2             [128, 128, 32, 32]        256
│    │    └─ReLU: 3-3                    [128, 128, 32, 32]        --
│    └─Sequential: 2-9                   [128, 128, 32, 32]        --
│    │    └─Conv2d: 3-4                  [128, 128, 32, 32]        147,584
│    │    └─BatchNorm2d: 3-5             [128, 128, 32, 32]        256
│    │    └─ReLU: 3-6                    [128, 128, 32, 32]        --
├─Sequential: 1-4                        [128, 256, 16, 16]        --
│    └─Conv2d: 2-10                      [128, 256, 32, 32]        295,168
│    └─BatchNorm2d: 2-11                 [128, 256, 32, 32]        512
│    └─ReLU: 2-12                        [128, 256, 32, 32]        --
│    └─MaxPool2d: 2-13                   [128, 256, 16, 16]        --
├─Sequential: 1-5                        [128, 512, 8, 8]          --
│    └─Conv2d: 2-14                      [128, 512, 16, 16]        1,180,160
│    └─BatchNorm2d: 2-15                 [128, 512, 16, 16]        1,024
│    └─ReLU: 2-16                        [128, 512, 16, 16]        --
│    └─MaxPool2d: 2-17                   [128, 512, 8, 8]          --
├─Sequential: 1-6                        [128, 512, 8, 8]          --
│    └─Sequential: 2-18                  [128, 512, 8, 8]          --
│    │    └─Conv2d: 3-7                  [128, 512, 8, 8]          2,359,808
│    │    └─BatchNorm2d: 3-8             [128, 512, 8, 8]          1,024
│    │    └─ReLU: 3-9                    [128, 512, 8, 8]          --
│    └─Sequential: 2-19                  [128, 512, 8, 8]          --
│    │    └─Conv2d: 3-10                 [128, 512, 8, 8]          2,359,808
│    │    └─BatchNorm2d: 3-11            [128, 512, 8, 8]          1,024
│    │    └─ReLU: 3-12                   [128, 512, 8, 8]          --
├─Sequential: 1-7                        [128, 1024, 4, 4]         --
│    └─Conv2d: 2-20                      [128, 1024, 8, 8]         4,719,616
│    └─BatchNorm2d: 2-21                 [128, 1024, 8, 8]         2,048
│    └─ReLU: 2-22                        [128, 1024, 8, 8]         --
│    └─MaxPool2d: 2-23                   [128, 1024, 4, 4]         --
├─Sequential: 1-8                        [128, 42]                 --
│    └─MaxPool2d: 2-24                   [128, 1024, 1, 1]         --
│    └─Flatten: 2-25                     [128, 1024]               --
│    └─Linear: 2-26                      [128, 42]                 43,050
==========================================================================================
Total params: 11,334,954
Trainable params: 11,334,954
Non-trainable params: 0
Total mult-adds (G): 233.04
==========================================================================================
Input size (MB): 6.29
Forward/backward pass size (MB): 3221.27
Params size (MB): 45.34
Estimated Total Size (MB): 3272.90
==========================================================================================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Model                                    [128, 42]                 --
├─Sequential: 1-1                        [128, 64, 64, 64]         --
│    └─Conv2d: 2-1                       [128, 64, 64, 64]         1,792
│    └─BatchNorm2d: 2-2                  [128, 64, 64, 64]         128
│    └─ReLU: 2-3                         [128, 64, 64, 64]         --
├─Sequential: 1-2                        [128, 128, 32, 32]        --
│    └─Conv2d: 2-4                       [128, 128, 64, 64]        73,856
│    └─BatchNorm2d: 2-5                  [128, 128, 64, 64]        256
│    └─ReLU: 2-6                         [128, 128, 64, 64]        --
│    └─MaxPool2d: 2-7                    [128, 128, 32, 32]        --
├─Sequential: 1-3                        [128, 128, 32, 32]        --
│    └─Sequential: 2-8                   [128, 128, 32, 32]        --
│    │    └─Conv2d: 3-1                  [128, 128, 32, 32]        147,584
│    │    └─BatchNorm2d: 3-2             [128, 128, 32, 32]        256
│    │    └─ReLU: 3-3                    [128, 128, 32, 32]        --
│    └─Sequential: 2-9                   [128, 128, 32, 32]        --
│    │    └─Conv2d: 3-4                  [128, 128, 32, 32]        147,584
│    │    └─BatchNorm2d: 3-5             [128, 128, 32, 32]        256
│    │    └─ReLU: 3-6                    [128, 128, 32, 32]        --
├─Sequential: 1-4                        [128, 256, 16, 16]        --
│    └─Conv2d: 2-10                      [128, 256, 32, 32]        295,168
│    └─BatchNorm2d: 2-11                 [128, 256, 32, 32]        512
│    └─ReLU: 2-12                        [128, 256, 32, 32]        --
│    └─MaxPool2d: 2-13                   [128, 256, 16, 16]        --
├─Sequential: 1-5                        [128, 512, 8, 8]          --
│    └─Conv2d: 2-14                      [128, 512, 16, 16]        1,180,160
│    └─BatchNorm2d: 2-15                 [128, 512, 16, 16]        1,024
│    └─ReLU: 2-16                        [128, 512, 16, 16]        --
│    └─MaxPool2d: 2-17                   [128, 512, 8, 8]          --
├─Sequential: 1-6                        [128, 512, 8, 8]          --
│    └─Sequential: 2-18                  [128, 512, 8, 8]          --
│    │    └─Conv2d: 3-7                  [128, 512, 8, 8]          2,359,808
│    │    └─BatchNorm2d: 3-8             [128, 512, 8, 8]          1,024
│    │    └─ReLU: 3-9                    [128, 512, 8, 8]          --
│    └─Sequential: 2-19                  [128, 512, 8, 8]          --
│    │    └─Conv2d: 3-10                 [128, 512, 8, 8]          2,359,808
│    │    └─BatchNorm2d: 3-11            [128, 512, 8, 8]          1,024
│    │    └─ReLU: 3-12                   [128, 512, 8, 8]          --
├─Sequential: 1-7                        [128, 1024, 4, 4]         --
│    └─Conv2d: 2-20                      [128, 1024, 8, 8]         4,719,616
│    └─BatchNorm2d: 2-21                 [128, 1024, 8, 8]         2,048
│    └─ReLU: 2-22                        [128, 1024, 8, 8]         --
│    └─MaxPool2d: 2-23                   [128, 1024, 4, 4]         --
├─Sequential: 1-8                        [128, 42]                 --
│    └─MaxPool2d: 2-24                   [128, 1024, 1, 1]         --
│    └─Flatten: 2-25                     [128, 1024]               --
│    └─Linear: 2-26                      [128, 42]                 43,050
==========================================================================================
Total params: 11,334,954
Trainable params: 11,334,954
Non-trainable params: 0
Total mult-adds (G): 233.04
==========================================================================================
Input size (MB): 6.29
Forward/backward pass size (MB): 3221.27
Params size (MB): 45.34
Estimated Total Size (MB): 3272.90
==========================================================================================
  0%|          | 0/100 [00:00<?, ?it/s][0] Acc: 0.1073 Avg. train/valid loss: 5.0814/3.4958
:   0%|          | 0/100 [00:30<?, ?it/s][0] Acc: 0.1073 Avg. train/valid loss: 5.0814/3.4958
:   1%|          | 1/100 [00:30<50:56, 30.88s/it][1] Acc: 0.3462 Avg. train/valid loss: 3.1966/2.7601
:   1%|          | 1/100 [01:01<50:56, 30.88s/it][1] Acc: 0.3462 Avg. train/valid loss: 3.1966/2.7601
:   2%|▏         | 2/100 [01:01<50:17, 30.79s/it][2] Acc: 0.5552 Avg. train/valid loss: 2.0264/1.6612
:   2%|▏         | 2/100 [01:33<50:17, 30.79s/it][2] Acc: 0.5552 Avg. train/valid loss: 2.0264/1.6612
:   3%|▎         | 3/100 [01:33<50:18, 31.12s/it][3] Acc: 0.7389 Avg. train/valid loss: 1.1780/1.0254
:   3%|▎         | 3/100 [02:05<50:18, 31.12s/it][3] Acc: 0.7389 Avg. train/valid loss: 1.1780/1.0254
:   4%|▍         | 4/100 [02:05<50:19, 31.46s/it][4] Acc: 0.7797 Avg. train/valid loss: 0.7332/0.9087
:   4%|▍         | 4/100 [02:36<50:19, 31.46s/it][4] Acc: 0.7797 Avg. train/valid loss: 0.7332/0.9087
:   5%|▌         | 5/100 [02:36<50:01, 31.59s/it]Saved weights with acc: 0.7797420024871826 | loss: 0.9087251424789429
[5] Acc: 0.8304 Avg. train/valid loss: 0.5230/0.6717
:   5%|▌         | 5/100 [03:08<50:01, 31.59s/it][5] Acc: 0.8304 Avg. train/valid loss: 0.5230/0.6717
:   6%|▌         | 6/100 [03:08<49:43, 31.74s/it]Saved weights with acc: 0.8303869962692261 | loss: 0.6717339158058167
[6] Acc: 0.8397 Avg. train/valid loss: 0.3387/0.6586
:   6%|▌         | 6/100 [03:40<49:43, 31.74s/it][6] Acc: 0.8397 Avg. train/valid loss: 0.3387/0.6586
:   7%|▋         | 7/100 [03:40<49:18, 31.81s/it]Saved weights with acc: 0.8397037982940674 | loss: 0.6586452722549438
[7] Acc: 0.8438 Avg. train/valid loss: 0.2260/0.5742
:   7%|▋         | 7/100 [04:13<49:18, 31.81s/it][7] Acc: 0.8438 Avg. train/valid loss: 0.2260/0.5742
:   8%|▊         | 8/100 [04:13<48:56, 31.92s/it]Saved weights with acc: 0.8437649607658386 | loss: 0.574155330657959
[8] Acc: 0.8791 Avg. train/valid loss: 0.1439/0.4742
:   8%|▊         | 8/100 [04:44<48:56, 31.92s/it][8] Acc: 0.8791 Avg. train/valid loss: 0.1439/0.4742
:   9%|▉         | 9/100 [04:44<48:19, 31.86s/it]Saved weights with acc: 0.8791208863258362 | loss: 0.47415658831596375
[9] Acc: 0.9135 Avg. train/valid loss: 0.0736/0.3762
:   9%|▉         | 9/100 [05:16<48:19, 31.86s/it][9] Acc: 0.9135 Avg. train/valid loss: 0.0736/0.3762
:  10%|█         | 10/100 [05:16<47:54, 31.94s/it]Saved weights with acc: 0.9135212898254395 | loss: 0.3761817216873169
[10] Acc: 0.9314 Avg. train/valid loss: 0.0348/0.3021
:  10%|█         | 10/100 [05:48<47:54, 31.94s/it][10] Acc: 0.9314 Avg. train/valid loss: 0.0348/0.3021
:  11%|█         | 11/100 [05:48<47:25, 31.98s/it]Saved weights with acc: 0.931438148021698 | loss: 0.30207473039627075
[11] Acc: 0.9381 Avg. train/valid loss: 0.0141/0.2747
:  11%|█         | 11/100 [06:21<47:25, 31.98s/it][11] Acc: 0.9381 Avg. train/valid loss: 0.0141/0.2747
:  12%|█▏        | 12/100 [06:21<46:59, 32.04s/it]Saved weights with acc: 0.9381271004676819 | loss: 0.2747282087802887
[12] Acc: 0.9412 Avg. train/valid loss: 0.0080/0.2769
:  12%|█▏        | 12/100 [06:53<46:59, 32.04s/it][12] Acc: 0.9412 Avg. train/valid loss: 0.0080/0.2769
:  13%|█▎        | 13/100 [06:53<46:32, 32.10s/it][13] Acc: 0.9396 Avg. train/valid loss: 0.0057/0.2826
:  13%|█▎        | 13/100 [07:25<46:32, 32.10s/it][13] Acc: 0.9396 Avg. train/valid loss: 0.0057/0.2826
:  14%|█▍        | 14/100 [07:25<45:56, 32.06s/it][14] Acc: 0.9419 Avg. train/valid loss: 0.0045/0.2675
:  14%|█▍        | 14/100 [07:57<45:56, 32.06s/it][14] Acc: 0.9419 Avg. train/valid loss: 0.0045/0.2675
:  15%|█▌        | 15/100 [07:57<45:23, 32.04s/it]Saved weights with acc: 0.9419493675231934 | loss: 0.2675442099571228
[15] Acc: 0.9408 Avg. train/valid loss: 0.0033/0.2708
:  15%|█▌        | 15/100 [08:29<45:23, 32.04s/it][15] Acc: 0.9408 Avg. train/valid loss: 0.0033/0.2708
:  16%|█▌        | 16/100 [08:29<44:52, 32.06s/it][16] Acc: 0.9393 Avg. train/valid loss: 0.0041/0.2756
:  16%|█▌        | 16/100 [09:01<44:52, 32.06s/it][16] Acc: 0.9393 Avg. train/valid loss: 0.0041/0.2756
:  17%|█▋        | 17/100 [09:01<44:13, 31.97s/it][17] Acc: 0.9417 Avg. train/valid loss: 0.0041/0.2647
:  17%|█▋        | 17/100 [09:33<44:13, 31.97s/it][17] Acc: 0.9417 Avg. train/valid loss: 0.0041/0.2647
:  18%|█▊        | 18/100 [09:33<43:43, 31.99s/it]Saved weights with acc: 0.9417104721069336 | loss: 0.2646929621696472
[18] Acc: 0.9436 Avg. train/valid loss: 0.0034/0.2627
:  18%|█▊        | 18/100 [10:05<43:43, 31.99s/it][18] Acc: 0.9436 Avg. train/valid loss: 0.0034/0.2627
:  19%|█▉        | 19/100 [10:05<43:12, 32.01s/it]Saved weights with acc: 0.9436215758323669 | loss: 0.2626841366291046
[19] Acc: 0.9391 Avg. train/valid loss: 0.0036/0.2846
:  19%|█▉        | 19/100 [10:37<43:12, 32.01s/it][19] Acc: 0.9391 Avg. train/valid loss: 0.0036/0.2846
:  20%|██        | 20/100 [10:37<42:44, 32.05s/it][20] Acc: 0.9393 Avg. train/valid loss: 0.0026/0.2824
:  20%|██        | 20/100 [11:09<42:44, 32.05s/it][20] Acc: 0.9393 Avg. train/valid loss: 0.0026/0.2824
:  21%|██        | 21/100 [11:09<42:09, 32.02s/it][21] Acc: 0.9424 Avg. train/valid loss: 0.0031/0.2733
:  21%|██        | 21/100 [11:41<42:09, 32.02s/it][21] Acc: 0.9424 Avg. train/valid loss: 0.0031/0.2733
:  22%|██▏       | 22/100 [11:41<41:34, 31.98s/it][22] Acc: 0.9427 Avg. train/valid loss: 0.0027/0.2619
:  22%|██▏       | 22/100 [12:13<41:34, 31.98s/it][22] Acc: 0.9427 Avg. train/valid loss: 0.0027/0.2619
:  23%|██▎       | 23/100 [12:13<40:57, 31.91s/it]Saved weights with acc: 0.9426660537719727 | loss: 0.2618768513202667
[23] Acc: 0.9412 Avg. train/valid loss: 0.0023/0.2639
:  23%|██▎       | 23/100 [12:45<40:57, 31.91s/it][23] Acc: 0.9412 Avg. train/valid loss: 0.0023/0.2639
:  24%|██▍       | 24/100 [12:45<40:39, 32.09s/it][24] Acc: 0.9431 Avg. train/valid loss: 0.0026/0.2705
:  24%|██▍       | 24/100 [13:17<40:39, 32.09s/it][24] Acc: 0.9431 Avg. train/valid loss: 0.0026/0.2705
:  25%|██▌       | 25/100 [13:17<40:06, 32.09s/it][25] Acc: 0.9415 Avg. train/valid loss: 0.0013/0.2620
:  25%|██▌       | 25/100 [13:49<40:06, 32.09s/it][25] Acc: 0.9415 Avg. train/valid loss: 0.0013/0.2620
:  26%|██▌       | 26/100 [13:49<39:32, 32.06s/it][26] Acc: 0.9429 Avg. train/valid loss: 0.0022/0.2666
:  26%|██▌       | 26/100 [14:21<39:32, 32.06s/it][26] Acc: 0.9429 Avg. train/valid loss: 0.0022/0.2666
:  27%|██▋       | 27/100 [14:21<38:51, 31.93s/it][27] Acc: 0.9429 Avg. train/valid loss: 0.0016/0.2778
:  27%|██▋       | 27/100 [14:52<38:51, 31.93s/it][27] Acc: 0.9429 Avg. train/valid loss: 0.0016/0.2778
:  28%|██▊       | 28/100 [14:52<38:12, 31.84s/it][28] Acc: 0.9422 Avg. train/valid loss: 0.0013/0.2649
:  28%|██▊       | 28/100 [15:24<38:12, 31.84s/it][28] Acc: 0.9422 Avg. train/valid loss: 0.0013/0.2649
:  29%|██▉       | 29/100 [15:24<37:41, 31.85s/it][29] Acc: 0.9434 Avg. train/valid loss: 0.0021/0.2628
:  29%|██▉       | 29/100 [15:56<37:41, 31.85s/it][29] Acc: 0.9434 Avg. train/valid loss: 0.0021/0.2628
:  30%|███       | 30/100 [15:56<37:05, 31.79s/it][30] Acc: 0.9439 Avg. train/valid loss: 0.0019/0.2658
:  30%|███       | 30/100 [16:28<37:05, 31.79s/it][30] Acc: 0.9439 Avg. train/valid loss: 0.0019/0.2658
:  31%|███       | 31/100 [16:28<36:40, 31.89s/it][31] Acc: 0.9458 Avg. train/valid loss: 0.0015/0.2666
:  31%|███       | 31/100 [17:00<36:40, 31.89s/it][31] Acc: 0.9458 Avg. train/valid loss: 0.0015/0.2666
:  32%|███▏      | 32/100 [17:00<36:11, 31.93s/it][32] Acc: 0.9424 Avg. train/valid loss: 0.0017/0.2684
:  32%|███▏      | 32/100 [17:32<36:11, 31.93s/it][32] Acc: 0.9424 Avg. train/valid loss: 0.0017/0.2684
:  33%|███▎      | 33/100 [17:32<35:35, 31.88s/it][33] Acc: 0.9443 Avg. train/valid loss: 0.0012/0.2646
:  33%|███▎      | 33/100 [18:04<35:35, 31.88s/it][33] Acc: 0.9443 Avg. train/valid loss: 0.0012/0.2646
:  34%|███▍      | 34/100 [18:04<35:12, 32.01s/it][34] Acc: 0.9441 Avg. train/valid loss: 0.0009/0.2645
:  34%|███▍      | 34/100 [18:36<35:12, 32.01s/it][34] Acc: 0.9441 Avg. train/valid loss: 0.0009/0.2645
:  35%|███▌      | 35/100 [18:36<34:39, 31.99s/it][35] Acc: 0.9439 Avg. train/valid loss: 0.0009/0.2643
:  35%|███▌      | 35/100 [19:08<34:39, 31.99s/it][35] Acc: 0.9439 Avg. train/valid loss: 0.0009/0.2643
:  36%|███▌      | 36/100 [19:08<34:05, 31.96s/it][36] Acc: 0.9453 Avg. train/valid loss: 0.0008/0.2624
:  36%|███▌      | 36/100 [19:40<34:05, 31.96s/it][36] Acc: 0.9453 Avg. train/valid loss: 0.0008/0.2624
:  37%|███▋      | 37/100 [19:40<33:29, 31.90s/it][37] Acc: 0.9441 Avg. train/valid loss: 0.0008/0.2645
:  37%|███▋      | 37/100 [20:12<33:29, 31.90s/it][37] Acc: 0.9441 Avg. train/valid loss: 0.0008/0.2645
:  38%|███▊      | 38/100 [20:12<32:57, 31.89s/it][38] Acc: 0.9446 Avg. train/valid loss: 0.0007/0.2665
:  38%|███▊      | 38/100 [20:44<32:57, 31.89s/it][38] Acc: 0.9446 Avg. train/valid loss: 0.0007/0.2665
:  39%|███▉      | 39/100 [20:44<32:29, 31.97s/it][39] Acc: 0.9431 Avg. train/valid loss: 0.0006/0.2642
:  39%|███▉      | 39/100 [21:15<32:29, 31.97s/it][39] Acc: 0.9431 Avg. train/valid loss: 0.0006/0.2642
:  40%|████      | 40/100 [21:15<31:49, 31.83s/it][40] Acc: 0.9451 Avg. train/valid loss: 0.0006/0.2667
:  40%|████      | 40/100 [21:47<31:49, 31.83s/it][40] Acc: 0.9451 Avg. train/valid loss: 0.0006/0.2667
:  41%|████      | 41/100 [21:47<31:13, 31.76s/it][41] Acc: 0.9441 Avg. train/valid loss: 0.0006/0.2634
:  41%|████      | 41/100 [22:18<31:13, 31.76s/it][41] Acc: 0.9441 Avg. train/valid loss: 0.0006/0.2634
:  42%|████▏     | 42/100 [22:18<30:37, 31.68s/it][42] Acc: 0.9439 Avg. train/valid loss: 0.0006/0.2641
:  42%|████▏     | 42/100 [22:50<30:37, 31.68s/it][42] Acc: 0.9439 Avg. train/valid loss: 0.0006/0.2641
:  43%|████▎     | 43/100 [22:50<30:06, 31.69s/it][43] Acc: 0.9441 Avg. train/valid loss: 0.0007/0.2629
:  43%|████▎     | 43/100 [23:22<30:06, 31.69s/it][43] Acc: 0.9441 Avg. train/valid loss: 0.0007/0.2629
:  44%|████▍     | 44/100 [23:22<29:34, 31.70s/it][44] Acc: 0.9448 Avg. train/valid loss: 0.0006/0.2634
:  44%|████▍     | 44/100 [23:54<29:34, 31.70s/it][44] Acc: 0.9448 Avg. train/valid loss: 0.0006/0.2634
:  45%|████▌     | 45/100 [23:54<29:06, 31.76s/it][45] Acc: 0.9451 Avg. train/valid loss: 0.0006/0.2645
:  45%|████▌     | 45/100 [24:27<29:06, 31.76s/it][45] Acc: 0.9451 Avg. train/valid loss: 0.0006/0.2645
:  46%|████▌     | 46/100 [24:27<28:57, 32.18s/it][46] Acc: 0.9436 Avg. train/valid loss: 0.0006/0.2670
:  46%|████▌     | 46/100 [24:58<28:57, 32.18s/it][46] Acc: 0.9436 Avg. train/valid loss: 0.0006/0.2670
:  47%|████▋     | 47/100 [24:58<28:16, 32.00s/it][47] Acc: 0.9446 Avg. train/valid loss: 0.0006/0.2617
:  47%|████▋     | 47/100 [25:30<28:16, 32.00s/it][47] Acc: 0.9446 Avg. train/valid loss: 0.0006/0.2617
:  48%|████▊     | 48/100 [25:30<27:45, 32.02s/it]Saved weights with acc: 0.944577157497406 | loss: 0.2616758346557617
[48] Acc: 0.9451 Avg. train/valid loss: 0.0006/0.2633
:  48%|████▊     | 48/100 [26:02<27:45, 32.02s/it][48] Acc: 0.9451 Avg. train/valid loss: 0.0006/0.2633
:  49%|████▉     | 49/100 [26:02<27:10, 31.97s/it][49] Acc: 0.9458 Avg. train/valid loss: 0.0005/0.2637
:  49%|████▉     | 49/100 [26:35<27:10, 31.97s/it][49] Acc: 0.9458 Avg. train/valid loss: 0.0005/0.2637
:  50%|█████     | 50/100 [26:35<26:43, 32.06s/it][50] Acc: 0.9446 Avg. train/valid loss: 0.0005/0.2635
:  50%|█████     | 50/100 [27:06<26:43, 32.06s/it][50] Acc: 0.9446 Avg. train/valid loss: 0.0005/0.2635
:  51%|█████     | 51/100 [27:06<26:06, 31.97s/it][51] Acc: 0.9443 Avg. train/valid loss: 0.0006/0.2633
:  51%|█████     | 51/100 [27:38<26:06, 31.97s/it][51] Acc: 0.9443 Avg. train/valid loss: 0.0006/0.2633
:  52%|█████▏    | 52/100 [27:38<25:31, 31.91s/it][52] Acc: 0.9443 Avg. train/valid loss: 0.0006/0.2661
:  52%|█████▏    | 52/100 [28:10<25:31, 31.91s/it][52] Acc: 0.9443 Avg. train/valid loss: 0.0006/0.2661
:  53%|█████▎    | 53/100 [28:10<24:57, 31.86s/it][53] Acc: 0.9446 Avg. train/valid loss: 0.0005/0.2625
:  53%|█████▎    | 53/100 [28:42<24:57, 31.86s/it][53] Acc: 0.9446 Avg. train/valid loss: 0.0005/0.2625
:  54%|█████▍    | 54/100 [28:42<24:29, 31.94s/it][54] Acc: 0.9443 Avg. train/valid loss: 0.0006/0.2639
:  54%|█████▍    | 54/100 [29:14<24:29, 31.94s/it][54] Acc: 0.9443 Avg. train/valid loss: 0.0006/0.2639
:  55%|█████▌    | 55/100 [29:14<23:55, 31.91s/it][55] Acc: 0.9434 Avg. train/valid loss: 0.0005/0.2642
:  55%|█████▌    | 55/100 [29:45<23:55, 31.91s/it][55] Acc: 0.9434 Avg. train/valid loss: 0.0005/0.2642
:  56%|█████▌    | 56/100 [29:45<23:19, 31.82s/it][56] Acc: 0.9439 Avg. train/valid loss: 0.0006/0.2629
:  56%|█████▌    | 56/100 [30:18<23:19, 31.82s/it][56] Acc: 0.9439 Avg. train/valid loss: 0.0006/0.2629
:  57%|█████▋    | 57/100 [30:18<22:56, 32.01s/it][57] Acc: 0.9448 Avg. train/valid loss: 0.0006/0.2642
:  57%|█████▋    | 57/100 [30:50<22:56, 32.01s/it][57] Acc: 0.9448 Avg. train/valid loss: 0.0006/0.2642
:  58%|█████▊    | 58/100 [30:50<22:21, 31.94s/it][58] Acc: 0.9427 Avg. train/valid loss: 0.0006/0.2646
:  58%|█████▊    | 58/100 [31:22<22:21, 31.94s/it][58] Acc: 0.9427 Avg. train/valid loss: 0.0006/0.2646
:  59%|█████▉    | 59/100 [31:22<21:49, 31.95s/it][59] Acc: 0.9439 Avg. train/valid loss: 0.0006/0.2625
:  59%|█████▉    | 59/100 [31:53<21:49, 31.95s/it][59] Acc: 0.9439 Avg. train/valid loss: 0.0006/0.2625
:  60%|██████    | 60/100 [31:53<21:12, 31.81s/it][60] Acc: 0.9460 Avg. train/valid loss: 0.0005/0.2657
:  60%|██████    | 60/100 [32:25<21:12, 31.81s/it][60] Acc: 0.9460 Avg. train/valid loss: 0.0005/0.2657
:  61%|██████    | 61/100 [32:25<20:38, 31.77s/it][61] Acc: 0.9446 Avg. train/valid loss: 0.0006/0.2641
:  61%|██████    | 61/100 [32:56<20:38, 31.77s/it][61] Acc: 0.9446 Avg. train/valid loss: 0.0006/0.2641
:  62%|██████▏   | 62/100 [32:56<20:05, 31.74s/it][62] Acc: 0.9448 Avg. train/valid loss: 0.0006/0.2647
:  62%|██████▏   | 62/100 [33:28<20:05, 31.74s/it][62] Acc: 0.9448 Avg. train/valid loss: 0.0006/0.2647
:  63%|██████▎   | 63/100 [33:28<19:30, 31.64s/it][63] Acc: 0.9453 Avg. train/valid loss: 0.0005/0.2642
:  63%|██████▎   | 63/100 [34:01<19:30, 31.64s/it][63] Acc: 0.9453 Avg. train/valid loss: 0.0005/0.2642
:  64%|██████▍   | 64/100 [34:01<19:14, 32.07s/it][64] Acc: 0.9446 Avg. train/valid loss: 0.0006/0.2631
:  64%|██████▍   | 64/100 [34:33<19:14, 32.07s/it][64] Acc: 0.9446 Avg. train/valid loss: 0.0006/0.2631
:  65%|██████▌   | 65/100 [34:33<18:39, 31.98s/it][65] Acc: 0.9455 Avg. train/valid loss: 0.0006/0.2644
:  65%|██████▌   | 65/100 [35:04<18:39, 31.98s/it][65] Acc: 0.9455 Avg. train/valid loss: 0.0006/0.2644
:  66%|██████▌   | 66/100 [35:04<18:04, 31.90s/it][66] Acc: 0.9446 Avg. train/valid loss: 0.0005/0.2650
:  66%|██████▌   | 66/100 [35:36<18:04, 31.90s/it][66] Acc: 0.9446 Avg. train/valid loss: 0.0005/0.2650
:  67%|██████▋   | 67/100 [35:36<17:29, 31.80s/it][67] Acc: 0.9443 Avg. train/valid loss: 0.0006/0.2623
:  67%|██████▋   | 67/100 [36:08<17:29, 31.80s/it][67] Acc: 0.9443 Avg. train/valid loss: 0.0006/0.2623
:  68%|██████▊   | 68/100 [36:08<16:58, 31.84s/it][68] Acc: 0.9453 Avg. train/valid loss: 0.0006/0.2648
:  68%|██████▊   | 68/100 [36:40<16:58, 31.84s/it][68] Acc: 0.9453 Avg. train/valid loss: 0.0006/0.2648
:  69%|██████▉   | 69/100 [36:40<16:25, 31.80s/it][69] Acc: 0.9443 Avg. train/valid loss: 0.0006/0.2635
:  69%|██████▉   | 69/100 [37:11<16:25, 31.80s/it][69] Acc: 0.9443 Avg. train/valid loss: 0.0006/0.2635
:  70%|███████   | 70/100 [37:11<15:53, 31.77s/it][70] Acc: 0.9446 Avg. train/valid loss: 0.0006/0.2646
:  70%|███████   | 70/100 [37:43<15:53, 31.77s/it][70] Acc: 0.9446 Avg. train/valid loss: 0.0006/0.2646
:  71%|███████   | 71/100 [37:43<15:24, 31.86s/it][71] Acc: 0.9446 Avg. train/valid loss: 0.0006/0.2646
:  71%|███████   | 71/100 [38:16<15:24, 31.86s/it][71] Acc: 0.9446 Avg. train/valid loss: 0.0006/0.2646
:  72%|███████▏  | 72/100 [38:16<14:54, 31.95s/it][72] Acc: 0.9439 Avg. train/valid loss: 0.0006/0.2645
:  72%|███████▏  | 72/100 [38:48<14:54, 31.95s/it][72] Acc: 0.9439 Avg. train/valid loss: 0.0006/0.2645
:  73%|███████▎  | 73/100 [38:48<14:24, 32.01s/it][73] Acc: 0.9441 Avg. train/valid loss: 0.0005/0.2640
:  73%|███████▎  | 73/100 [39:20<14:24, 32.01s/it][73] Acc: 0.9441 Avg. train/valid loss: 0.0005/0.2640
:  74%|███████▍  | 74/100 [39:20<13:53, 32.06s/it][74] Acc: 0.9441 Avg. train/valid loss: 0.0005/0.2624
:  74%|███████▍  | 74/100 [39:52<13:53, 32.06s/it][74] Acc: 0.9441 Avg. train/valid loss: 0.0005/0.2624
:  75%|███████▌  | 75/100 [39:52<13:19, 31.97s/it][75] Acc: 0.9434 Avg. train/valid loss: 0.0006/0.2651
:  75%|███████▌  | 75/100 [40:24<13:19, 31.97s/it][75] Acc: 0.9434 Avg. train/valid loss: 0.0006/0.2651
:  76%|███████▌  | 76/100 [40:24<12:49, 32.05s/it][76] Acc: 0.9448 Avg. train/valid loss: 0.0006/0.2644
:  76%|███████▌  | 76/100 [40:56<12:49, 32.05s/it][76] Acc: 0.9448 Avg. train/valid loss: 0.0006/0.2644
:  77%|███████▋  | 77/100 [40:56<12:15, 32.00s/it][77] Acc: 0.9448 Avg. train/valid loss: 0.0006/0.2640
:  77%|███████▋  | 77/100 [41:28<12:15, 32.00s/it][77] Acc: 0.9448 Avg. train/valid loss: 0.0006/0.2640
:  78%|███████▊  | 78/100 [41:28<11:42, 31.93s/it][78] Acc: 0.9439 Avg. train/valid loss: 0.0005/0.2674
:  78%|███████▊  | 78/100 [42:00<11:42, 31.93s/it][78] Acc: 0.9439 Avg. train/valid loss: 0.0005/0.2674
:  79%|███████▉  | 79/100 [42:00<11:10, 31.94s/it][79] Acc: 0.9446 Avg. train/valid loss: 0.0006/0.2638
:  79%|███████▉  | 79/100 [42:31<11:10, 31.94s/it][79] Acc: 0.9446 Avg. train/valid loss: 0.0006/0.2638
:  80%|████████  | 80/100 [42:31<10:37, 31.89s/it][80] Acc: 0.9453 Avg. train/valid loss: 0.0005/0.2634
:  80%|████████  | 80/100 [43:03<10:37, 31.89s/it][80] Acc: 0.9453 Avg. train/valid loss: 0.0005/0.2634
:  81%|████████  | 81/100 [43:03<10:04, 31.82s/it][81] Acc: 0.9451 Avg. train/valid loss: 0.0006/0.2668
:  81%|████████  | 81/100 [43:35<10:04, 31.82s/it][81] Acc: 0.9451 Avg. train/valid loss: 0.0006/0.2668
:  82%|████████▏ | 82/100 [43:35<09:31, 31.76s/it][82] Acc: 0.9443 Avg. train/valid loss: 0.0006/0.2631
:  82%|████████▏ | 82/100 [44:06<09:31, 31.76s/it][82] Acc: 0.9443 Avg. train/valid loss: 0.0006/0.2631
:  83%|████████▎ | 83/100 [44:06<08:59, 31.74s/it][83] Acc: 0.9446 Avg. train/valid loss: 0.0006/0.2616
:  83%|████████▎ | 83/100 [44:38<08:59, 31.74s/it][83] Acc: 0.9446 Avg. train/valid loss: 0.0006/0.2616
:  84%|████████▍ | 84/100 [44:38<08:28, 31.78s/it]Saved weights with acc: 0.944577157497406 | loss: 0.2615935802459717
[84] Acc: 0.9443 Avg. train/valid loss: 0.0006/0.2652
:  84%|████████▍ | 84/100 [45:10<08:28, 31.78s/it][84] Acc: 0.9443 Avg. train/valid loss: 0.0006/0.2652
:  85%|████████▌ | 85/100 [45:10<07:56, 31.79s/it][85] Acc: 0.9446 Avg. train/valid loss: 0.0006/0.2640
:  85%|████████▌ | 85/100 [45:41<07:56, 31.79s/it][85] Acc: 0.9446 Avg. train/valid loss: 0.0006/0.2640
:  86%|████████▌ | 86/100 [45:41<07:23, 31.69s/it][86] Acc: 0.9436 Avg. train/valid loss: 0.0006/0.2644
:  86%|████████▌ | 86/100 [46:14<07:23, 31.69s/it][86] Acc: 0.9436 Avg. train/valid loss: 0.0006/0.2644
:  87%|████████▋ | 87/100 [46:14<06:55, 31.97s/it][87] Acc: 0.9434 Avg. train/valid loss: 0.0005/0.2632
:  87%|████████▋ | 87/100 [46:46<06:55, 31.97s/it][87] Acc: 0.9434 Avg. train/valid loss: 0.0005/0.2632
:  88%|████████▊ | 88/100 [46:46<06:23, 31.95s/it][88] Acc: 0.9434 Avg. train/valid loss: 0.0005/0.2670
:  88%|████████▊ | 88/100 [47:18<06:23, 31.95s/it][88] Acc: 0.9434 Avg. train/valid loss: 0.0005/0.2670
:  89%|████████▉ | 89/100 [47:18<05:51, 31.96s/it][89] Acc: 0.9443 Avg. train/valid loss: 0.0006/0.2637
:  89%|████████▉ | 89/100 [47:50<05:51, 31.96s/it][89] Acc: 0.9443 Avg. train/valid loss: 0.0006/0.2637
:  90%|█████████ | 90/100 [47:50<05:19, 31.99s/it][90] Acc: 0.9441 Avg. train/valid loss: 0.0006/0.2658
:  90%|█████████ | 90/100 [48:22<05:19, 31.99s/it][90] Acc: 0.9441 Avg. train/valid loss: 0.0006/0.2658
:  91%|█████████ | 91/100 [48:22<04:46, 31.87s/it][91] Acc: 0.9446 Avg. train/valid loss: 0.0005/0.2625
:  91%|█████████ | 91/100 [48:54<04:46, 31.87s/it][91] Acc: 0.9446 Avg. train/valid loss: 0.0005/0.2625
:  92%|█████████▏| 92/100 [48:54<04:15, 31.91s/it][92] Acc: 0.9422 Avg. train/valid loss: 0.0006/0.2643
:  92%|█████████▏| 92/100 [49:25<04:15, 31.91s/it][92] Acc: 0.9422 Avg. train/valid loss: 0.0006/0.2643
:  93%|█████████▎| 93/100 [49:25<03:42, 31.85s/it][93] Acc: 0.9446 Avg. train/valid loss: 0.0006/0.2664
:  93%|█████████▎| 93/100 [49:57<03:42, 31.85s/it][93] Acc: 0.9446 Avg. train/valid loss: 0.0006/0.2664
:  94%|█████████▍| 94/100 [49:57<03:11, 31.86s/it][94] Acc: 0.9441 Avg. train/valid loss: 0.0005/0.2679
:  94%|█████████▍| 94/100 [50:29<03:11, 31.86s/it][94] Acc: 0.9441 Avg. train/valid loss: 0.0005/0.2679
:  95%|█████████▌| 95/100 [50:29<02:38, 31.77s/it][95] Acc: 0.9448 Avg. train/valid loss: 0.0006/0.2644
:  95%|█████████▌| 95/100 [51:01<02:38, 31.77s/it][95] Acc: 0.9448 Avg. train/valid loss: 0.0006/0.2644
:  96%|█████████▌| 96/100 [51:01<02:07, 31.80s/it][96] Acc: 0.9439 Avg. train/valid loss: 0.0005/0.2637
:  96%|█████████▌| 96/100 [51:33<02:07, 31.80s/it][96] Acc: 0.9439 Avg. train/valid loss: 0.0005/0.2637
:  97%|█████████▋| 97/100 [51:33<01:35, 31.84s/it][97] Acc: 0.9446 Avg. train/valid loss: 0.0005/0.2629
:  97%|█████████▋| 97/100 [52:04<01:35, 31.84s/it][97] Acc: 0.9446 Avg. train/valid loss: 0.0005/0.2629
:  98%|█████████▊| 98/100 [52:04<01:03, 31.75s/it][98] Acc: 0.9443 Avg. train/valid loss: 0.0006/0.2638
:  98%|█████████▊| 98/100 [52:36<01:03, 31.75s/it][98] Acc: 0.9443 Avg. train/valid loss: 0.0006/0.2638
:  99%|█████████▉| 99/100 [52:36<00:31, 31.67s/it][99] Acc: 0.9436 Avg. train/valid loss: 0.0006/0.2629
:  99%|█████████▉| 99/100 [53:07<00:31, 31.67s/it][99] Acc: 0.9436 Avg. train/valid loss: 0.0006/0.2629
: 100%|██████████| 100/100 [53:07<00:00, 31.69s/it][99] Acc: 0.9436 Avg. train/valid loss: 0.0006/0.2629
: 100%|██████████| 100/100 [53:07<00:00, 31.88s/it]
Traceback (most recent call last):
  File "/home/e.babenko1/AI_Tasks/01_Task/main2.py", line 326, in <module>
    for classname, accuracy in test_accuracy_per_class(model, valid_dataloader).items():
  File "/home/e.babenko1/AI_Tasks/01_Task/main2.py", line 321, in test_accuracy_per_class
    accuracy = (100 * float(correct_count)) / total_pred[classname]
ZeroDivisionError: float division by zero
