{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join as pjoin\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import torchmetrics.classification as metrics\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import torchinfo\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from additonFunc import uniqufy_path, create_image_plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Иницилизация ключевых значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "WEIGHT_SAVER = \"last\" # \"all\" / \"nothing\" / \"last\"\n",
    "\n",
    "CLASS_NAMES = ['other', 'road']\n",
    "CLASS_RGB_VALUES = [[0,0,0], [255, 255, 255]]\n",
    "\n",
    "NORMALIZE_MEAN_IMG = [0.4295, 0.4325, 0.3961]\n",
    "NORMALIZE_DEVIATIONS_IMG = [0.2267, 0.2192, 0.2240]\n",
    "\n",
    "CROP_SIZE = (256, 256)\n",
    "PADDED_SIZE = (1536, 1536)\n",
    "\n",
    "NUM_WORKERS = 2\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TBpath = uniqufy_path(\"TB_cache/roads\")\n",
    "TBwriter = SummaryWriter(TBpath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "prepare_to_network = A.Lambda(image=to_tensor, mask=to_tensor)\n",
    "\n",
    "train_transform= A.Compose(\n",
    "    [\n",
    "        A.RandomCrop(*CROP_SIZE, always_apply=True),\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.HorizontalFlip(p=1),\n",
    "                A.VerticalFlip(p=1),\n",
    "                A.RandomRotate90(p=1),\n",
    "            ],\n",
    "            p=0.75,\n",
    "        ),\n",
    "        A.Normalize(mean=NORMALIZE_MEAN_IMG, std=NORMALIZE_DEVIATIONS_IMG, always_apply=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "valid_transform = A.Compose(\n",
    "    [\n",
    "        A.PadIfNeeded(*PADDED_SIZE, always_apply=True, border_mode=cv2.BORDER_CONSTANT),\n",
    "        A.Normalize(mean=NORMALIZE_MEAN_IMG, std=NORMALIZE_DEVIATIONS_IMG, always_apply=True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(label, label_values):\n",
    "    semantic_map = []\n",
    "    for colour in label_values:\n",
    "        equality = np.equal(label, colour)\n",
    "        class_map = np.all(equality, axis = -1)\n",
    "        semantic_map.append(class_map)\n",
    "    semantic_map = np.stack(semantic_map, axis=-1)\n",
    "    return semantic_map\n",
    "\n",
    "def reverse_one_hot(image):\n",
    "    x = np.argmax(image, axis = -1)\n",
    "    return x\n",
    "\n",
    "def colour_code_segmentation(image, label_values):\n",
    "    colour_codes = np.array(label_values)\n",
    "    x = colour_codes[image.astype(int)]\n",
    "    return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset's\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoadsDataset(Dataset):\n",
    "    def __init__(self, values_dir, labels_dir, class_rgb_values=None, transform=None, readyToNetwork=None):\n",
    "        self.values_dir = values_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.class_rgb_values = class_rgb_values\n",
    "        self.images = [pjoin(self.values_dir, filename) for filename in sorted(os.listdir(self.values_dir))]\n",
    "        self.labels = [pjoin(self.labels_dir, filename) for filename in sorted(os.listdir(self.labels_dir))]\n",
    "        self.transform = transform\n",
    "        self.readyToNetwork = readyToNetwork\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.images[index]\n",
    "        label_path = self.labels[index]\n",
    "\n",
    "        image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "        label = cv2.cvtColor(cv2.imread(label_path), cv2.COLOR_BGR2RGB)\n",
    "        label = one_hot_encode(label, self.class_rgb_values).astype('float')\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(image=image, mask=label)\n",
    "            image, label = sample['image'], sample['mask']\n",
    "        if self.readyToNetwork:\n",
    "            sample = self.readyToNetwork(image=image, mask=label)\n",
    "            image, label = sample['image'], sample['mask']\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataset = RoadsDataset(\"dataset/tiff/test\", \"dataset/tiff/test_labels\",\n",
    "                       class_rgb_values=CLASS_RGB_VALUES, transform=train_transform)\n",
    "\n",
    "for i in range(10):\n",
    "    image, mask = sample_dataset[np.random.randint(0, len(sample_dataset))]\n",
    "    TBwriter.add_figure(f'train samples', create_image_plot(origin=image, true=colour_code_segmentation(\n",
    "        reverse_one_hot(mask), CLASS_RGB_VALUES)), global_step=i)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, inC : int, outC : int, kernel_size, **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        if isinstance(kernel_size, int):\n",
    "            kernel_size = (kernel_size, kernel_size)\n",
    "        self.in_channels = inC\n",
    "        self.out_channels = outC\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv = nn.Conv2d(inC, outC, kernel_size, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(outC)\n",
    "        self.activation = nn.ReLU(True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return self.activation(x)\n",
    "\n",
    "class DeConvBlock(nn.Module):\n",
    "    def __init__(self, inC : int, outC : int, kernel_size, **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        if isinstance(kernel_size, int):\n",
    "            kernel_size = (kernel_size, kernel_size)\n",
    "        self.in_channels = inC\n",
    "        self.out_channels = outC\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv = nn.ConvTranspose2d(inC, outC, kernel_size, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(outC)\n",
    "        self.activation = nn.ReLU(True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return self.activation(x)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, inC, outC = 0, interC = -1, block_expansion = 4):\n",
    "        super().__init__()\n",
    "        self.block_expansion = block_expansion\n",
    "\n",
    "        self.downConv = None\n",
    "        self.upConv = None\n",
    "\n",
    "        if interC > 0:\n",
    "            self.downConv = ConvBlock(inC, interC, 1)\n",
    "        elif interC < 0:\n",
    "            if interC == -1:\n",
    "                interC = inC * self.block_expansion\n",
    "            else:\n",
    "                interC = inC * -interC\n",
    "            self.downConv = ConvBlock(inC, interC, 1)\n",
    "        else:\n",
    "            interC = inC\n",
    "\n",
    "        self.mainConv = ConvBlock(interC, interC, 3, padding=1, groups=interC)\n",
    "\n",
    "        if outC > 0:\n",
    "            self.upConv = ConvBlock(interC, outC, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.downConv:\n",
    "            x = self.downConv(x)\n",
    "        x = self.mainConv(x)\n",
    "        if self.upConv:\n",
    "            x = self.upConv(x)\n",
    "        return x\n",
    "\n",
    "class ResidualStepBlock(nn.Module):\n",
    "    def __init__(self, inC, outC, global_block_expansion, interSize = 4, inter_block_expansion = 2):\n",
    "        super().__init__()\n",
    "\n",
    "        _innerConvs = []\n",
    "        previousC = inC\n",
    "        for stepC in range(inC, outC, (outC-inC)//interSize):\n",
    "            _innerConvs.append(ResidualBlock(previousC, stepC, block_expansion=inter_block_expansion))\n",
    "            previousC = stepC\n",
    "        _innerConvs.append(ResidualBlock(previousC, outC, block_expansion=inter_block_expansion))\n",
    "        \n",
    "        self.innerConvs = nn.Sequential(*_innerConvs)\n",
    "        if global_block_expansion > 0:\n",
    "            self.spatialConv = ConvBlock(outC, outC, 3, stride=global_block_expansion, padding=1)\n",
    "        else:\n",
    "            self.spatialConv = DeConvBlock(outC, outC, 4, stride=-global_block_expansion, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.innerConvs(x)\n",
    "        x = self.spatialConv(x)\n",
    "        return x\n",
    "\n",
    "class MyEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_1 = ConvBlock(3, 64, 3, stride=4, padding=1)\n",
    "\n",
    "        self.conv_2_residual = ResidualStepBlock(64, 96, global_block_expansion=2, interSize=2)\n",
    "\n",
    "        self.conv_3_residual = ResidualStepBlock(96, 128, global_block_expansion=2, interSize=4)\n",
    "\n",
    "        self.conv_4_residual = ResidualStepBlock(128, 256, global_block_expansion=2, interSize=4)\n",
    "\n",
    "        self.conv_5_residual = ResidualStepBlock(256, 512, global_block_expansion=2, interSize=8)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        xs = [x]\n",
    "        xs.append(self.conv_1(xs[-1]))\n",
    "        xs.append(self.conv_2_residual(xs[-1]))\n",
    "        xs.append(self.conv_3_residual(xs[-1]))\n",
    "        xs.append(self.conv_4_residual(xs[-1]))\n",
    "        xs.append(self.conv_5_residual(xs[-1]))\n",
    "        return xs\n",
    "\n",
    "class MyDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.deconv_1_residual = ResidualStepBlock(512, 256, global_block_expansion=-2, interSize=8)\n",
    "\n",
    "        self.deconv_2_residual = ResidualStepBlock(256, 128, global_block_expansion=-2, interSize=4)\n",
    "\n",
    "        self.deconv_3_residual = ResidualStepBlock(128, 96, global_block_expansion=-2, interSize=4)\n",
    "\n",
    "        self.deconv_4_residual = ResidualStepBlock(96, 64, global_block_expansion=-2, interSize=2)\n",
    "\n",
    "        self.deconv_5 = DeConvBlock(64, 3, 4, stride=4)\n",
    "    \n",
    "    def forward(self, encoder_samples):\n",
    "        x = self.deconv_1_residual(encoder_samples[-1]) + encoder_samples[-2]\n",
    "        x = self.deconv_2_residual(x) + encoder_samples[-3]\n",
    "        x = self.deconv_3_residual(x) + encoder_samples[-4]\n",
    "        x = self.deconv_4_residual(x) + encoder_samples[-5]\n",
    "        x = self.deconv_5(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MyUnet(nn.Module):\n",
    "    def __init__(self, outClasses : int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = MyEncoder()\n",
    "        self.decoder = MyDecoder()\n",
    "\n",
    "        self.classificator = ConvBlock(3, outClasses, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder_xs = self.encoder(x)\n",
    "        x = self.decoder(encoder_xs)\n",
    "        x = self.classificator(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================================================================================================================================================================================\n",
      "Layer (type (var_name))                                      Input Shape               Output Shape              Param #                   Param %                   Kernel Shape              Mult-Adds                 Trainable\n",
      "===========================================================================================================================================================================================================================================\n",
      "Unet (Unet)                                                  [32, 3, 256, 256]         [32, 2, 256, 256]         --                             --                   --                        --                        True\n",
      "├─MobileNetV3Encoder (encoder)                               [32, 3, 256, 256]         [32, 3, 256, 256]         --                             --                   --                        --                        True\n",
      "│    └─MobileNetV3Features (model)                           --                        --                        --                             --                   --                        --                        True\n",
      "│    │    └─Conv2dSame (conv_stem)                           [32, 3, 256, 256]         [32, 16, 128, 128]        432                         0.01%                   [3, 3]                    226,492,416               True\n",
      "│    │    └─BatchNorm2d (bn1)                                [32, 16, 128, 128]        [32, 16, 128, 128]        32                          0.00%                   --                        1,024                     True\n",
      "│    │    └─Hardswish (act1)                                 [32, 16, 128, 128]        [32, 16, 128, 128]        --                             --                   --                        --                        --\n",
      "│    │    └─Sequential (blocks)                              --                        --                        2,971,488                  44.44%                   --                        --                        True\n",
      "├─UnetDecoder (decoder)                                      [32, 3, 256, 256]         [32, 16, 256, 256]        --                             --                   --                        --                        True\n",
      "│    └─Identity (center)                                     [32, 960, 8, 8]           [32, 960, 8, 8]           --                             --                   --                        --                        --\n",
      "│    └─ModuleList (blocks)                                   --                        --                        --                             --                   --                        --                        True\n",
      "│    │    └─DecoderBlock (0)                                 [32, 960, 8, 8]           [32, 256, 16, 16]         3,060,736                  45.78%                   --                        25,065,193,472            True\n",
      "│    │    └─DecoderBlock (1)                                 [32, 256, 16, 16]         [32, 128, 32, 32]         488,960                     7.31%                   --                        16,005,480,448            True\n",
      "│    │    └─DecoderBlock (2)                                 [32, 128, 32, 32]         [32, 64, 64, 64]          124,672                     1.86%                   --                        16,307,462,144            True\n",
      "│    │    └─DecoderBlock (3)                                 [32, 64, 64, 64]          [32, 32, 128, 128]        32,384                      0.48%                   --                        16,911,437,824            True\n",
      "│    │    └─DecoderBlock (4)                                 [32, 32, 128, 128]        [32, 16, 256, 256]        6,976                       0.10%                   --                        14,495,516,672            True\n",
      "├─SegmentationHead (segmentation_head)                       [32, 16, 256, 256]        [32, 2, 256, 256]         --                             --                   --                        --                        True\n",
      "│    └─Conv2d (0)                                            [32, 16, 256, 256]        [32, 2, 256, 256]         290                         0.00%                   [3, 3]                    608,174,080               True\n",
      "│    └─Identity (1)                                          [32, 2, 256, 256]         [32, 2, 256, 256]         --                             --                   --                        --                        --\n",
      "│    └─Activation (2)                                        [32, 2, 256, 256]         [32, 2, 256, 256]         --                             --                   --                        --                        --\n",
      "│    │    └─ReLU (activation)                                [32, 2, 256, 256]         [32, 2, 256, 256]         --                             --                   --                        --                        --\n",
      "===========================================================================================================================================================================================================================================\n",
      "Total params: 6,685,970\n",
      "Trainable params: 6,685,970\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 98.33\n",
      "===========================================================================================================================================================================================================================================\n",
      "Input size (MB): 25.17\n",
      "Forward/backward pass size (MB): 3653.49\n",
      "Params size (MB): 26.65\n",
      "Estimated Total Size (MB): 3705.30\n",
      "===========================================================================================================================================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sega/progs/AI_Tasks/AIenv/lib/python3.10/site-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
      "/home/sega/progs/AI_Tasks/AIenv/lib/python3.10/site-packages/torch/storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return super().__sizeof__() + self.nbytes()\n"
     ]
    }
   ],
   "source": [
    "# model = MyUnet(2)\n",
    "# ENCODER = 'timm-mobilenetv3_large_100'\n",
    "# CLASSES = CLASS_NAMES\n",
    "# ACTIVATION = nn.ReLU\n",
    "\n",
    "# model = smp.Unet(\n",
    "#     encoder_name=ENCODER, \n",
    "#     classes=len(CLASSES), \n",
    "#     activation=ACTIVATION,\n",
    "# )\n",
    "\n",
    "# print(model_sum := torchinfo.summary(model, depth=3, input_size=(BATCH_SIZE, 3, *CROP_SIZE), row_settings=[\"var_names\"], verbose=0, col_names=[\n",
    "#       \"input_size\", \"output_size\", \"num_params\", \"params_percent\", \"kernel_size\", \"mult_adds\", \"trainable\"]))\n",
    "\n",
    "# dummy_input = torch.randn(1, 3, *CROP_SIZE)\n",
    "# torch.onnx.export(\n",
    "#             model.cpu(),\n",
    "#             dummy_input,\n",
    "#             \"model.onnx\",\n",
    "#         )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RoadsDataset(\"dataset/tiff/train\", \"dataset/tiff/train_labels\",\n",
    "                       class_rgb_values=CLASS_RGB_VALUES, transform=train_transform, readyToNetwork=prepare_to_network)\n",
    "valid_dataset = RoadsDataset(\"dataset/tiff/val\", \"dataset/tiff/val_labels\",\n",
    "                       class_rgb_values=CLASS_RGB_VALUES, transform=valid_transform, readyToNetwork=prepare_to_network)\n",
    "test_dataset = RoadsDataset(\"dataset/tiff/test\", \"dataset/tiff/test_labels\",\n",
    "                       class_rgb_values=CLASS_RGB_VALUES, transform=valid_transform, readyToNetwork=prepare_to_network)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=1,\n",
    "    num_workers=0,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================================================================================================================================================================================\n",
      "Layer (type (var_name))                            Input Shape               Output Shape              Param #                   Param %                   Kernel Shape              Mult-Adds                 Trainable\n",
      "=================================================================================================================================================================================================================================\n",
      "MyUnet (MyUnet)                                    [32, 3, 256, 256]         [32, 2, 256, 256]         --                             --                   --                        --                        True\n",
      "├─MyEncoder (encoder)                              [32, 3, 256, 256]         [32, 3, 256, 256]         --                             --                   --                        --                        True\n",
      "│    └─ConvBlock (conv_1)                          [32, 3, 256, 256]         [32, 64, 64, 64]          --                             --                   [3, 3]                    --                        True\n",
      "│    │    └─Conv2d (conv)                          [32, 3, 256, 256]         [32, 64, 64, 64]          1,792                       0.01%                   [3, 3]                    234,881,024               True\n",
      "│    │    └─BatchNorm2d (bn)                       [32, 64, 64, 64]          [32, 64, 64, 64]          128                         0.00%                   --                        4,096                     True\n",
      "│    │    └─ReLU (activation)                      [32, 64, 64, 64]          [32, 64, 64, 64]          --                             --                   --                        --                        --\n",
      "│    └─ResidualStepBlock (conv_2_residual)         [32, 64, 64, 64]          [32, 96, 32, 32]          --                             --                   --                        --                        True\n",
      "│    │    └─Sequential (innerConvs)                [32, 64, 64, 64]          [32, 96, 64, 64]          69,936                      0.38%                   --                        8,885,701,632             True\n",
      "│    │    └─ConvBlock (spatialConv)                [32, 96, 64, 64]          [32, 96, 32, 32]          83,232                      0.45%                   [3, 3]                    2,721,060,864             True\n",
      "│    └─ResidualStepBlock (conv_3_residual)         [32, 96, 32, 32]          [32, 128, 16, 16]         --                             --                   --                        --                        True\n",
      "│    │    └─Sequential (innerConvs)                [32, 96, 32, 32]          [32, 128, 32, 32]         249,200                     1.36%                   --                        7,990,844,416             True\n",
      "│    │    └─ConvBlock (spatialConv)                [32, 128, 32, 32]         [32, 128, 16, 16]         147,840                     0.81%                   [3, 3]                    1,209,016,320             True\n",
      "│    └─ResidualStepBlock (conv_4_residual)         [32, 128, 16, 16]         [32, 256, 8, 8]           --                             --                   --                        --                        True\n",
      "│    │    └─Sequential (innerConvs)                [32, 128, 16, 16]         [32, 256, 16, 16]         654,528                     3.56%                   --                        5,291,913,216             True\n",
      "│    │    └─ConvBlock (spatialConv)                [32, 256, 16, 16]         [32, 256, 8, 8]           590,592                     3.22%                   [3, 3]                    1,208,500,224             True\n",
      "│    └─ResidualStepBlock (conv_5_residual)         [32, 256, 8, 8]           [32, 512, 4, 4]           --                             --                   --                        --                        True\n",
      "│    │    └─Sequential (innerConvs)                [32, 256, 8, 8]           [32, 512, 8, 8]           5,062,528                  27.57%                   --                        10,302,513,152            True\n",
      "│    │    └─ConvBlock (spatialConv)                [32, 512, 8, 8]           [32, 512, 4, 4]           2,360,832                  12.86%                   [3, 3]                    1,208,254,464             True\n",
      "├─MyDecoder (decoder)                              [32, 3, 256, 256]         [32, 3, 256, 256]         --                             --                   --                        --                        True\n",
      "│    └─ResidualStepBlock (deconv_1_residual)       [32, 512, 4, 4]           [32, 256, 8, 8]           --                             --                   --                        --                        True\n",
      "│    │    └─Sequential (innerConvs)                [32, 512, 4, 4]           [32, 256, 4, 4]           6,257,536                  34.08%                   --                        3,186,286,592             True\n",
      "│    │    └─DeConvBlock (spatialConv)              [32, 256, 4, 4]           [32, 256, 8, 8]           1,049,344                   5.72%                   [4, 4]                    2,148,024,320             True\n",
      "│    └─ResidualStepBlock (deconv_2_residual)       [32, 256, 8, 8]           [32, 128, 16, 16]         --                             --                   --                        --                        True\n",
      "│    │    └─Sequential (innerConvs)                [32, 256, 8, 8]           [32, 128, 8, 8]           957,120                     5.21%                   --                        1,938,763,776             True\n",
      "│    │    └─DeConvBlock (spatialConv)              [32, 128, 8, 8]           [32, 128, 16, 16]         262,528                     1.43%                   [4, 4]                    2,148,540,416             True\n",
      "│    └─ResidualStepBlock (deconv_3_residual)       [32, 128, 16, 16]         [32, 96, 32, 32]          --                             --                   --                        --                        True\n",
      "│    │    └─Sequential (innerConvs)                [32, 128, 16, 16]         [32, 96, 16, 16]          294,128                     1.60%                   --                        2,361,711,616             True\n",
      "│    │    └─DeConvBlock (spatialConv)              [32, 96, 16, 16]          [32, 96, 32, 32]          147,744                     0.80%                   [4, 4]                    4,834,990,080             True\n",
      "│    └─ResidualStepBlock (deconv_4_residual)       [32, 96, 32, 32]          [32, 64, 64, 64]          --                             --                   --                        --                        True\n",
      "│    │    └─Sequential (innerConvs)                [32, 96, 32, 32]          [32, 64, 32, 32]          102,576                     0.56%                   --                        3,274,263,552             True\n",
      "│    │    └─DeConvBlock (spatialConv)              [32, 64, 32, 32]          [32, 64, 64, 64]          65,728                      0.36%                   [4, 4]                    8,598,327,296             True\n",
      "│    └─DeConvBlock (deconv_5)                      [32, 64, 64, 64]          [32, 3, 256, 256]         --                             --                   [4, 4]                    --                        True\n",
      "│    │    └─ConvTranspose2d (conv)                 [32, 64, 64, 64]          [32, 3, 256, 256]         3,075                       0.02%                   [4, 4]                    6,448,742,400             True\n",
      "│    │    └─BatchNorm2d (bn)                       [32, 3, 256, 256]         [32, 3, 256, 256]         6                           0.00%                   --                        192                       True\n",
      "│    │    └─ReLU (activation)                      [32, 3, 256, 256]         [32, 3, 256, 256]         --                             --                   --                        --                        --\n",
      "├─ConvBlock (classificator)                        [32, 3, 256, 256]         [32, 2, 256, 256]         --                             --                   [3, 3]                    --                        True\n",
      "│    └─Conv2d (conv)                               [32, 3, 256, 256]         [32, 2, 256, 256]         56                          0.00%                   [3, 3]                    117,440,512               True\n",
      "│    └─BatchNorm2d (bn)                            [32, 2, 256, 256]         [32, 2, 256, 256]         4                           0.00%                   --                        128                       True\n",
      "│    └─ReLU (activation)                           [32, 2, 256, 256]         [32, 2, 256, 256]         --                             --                   --                        --                        --\n",
      "=================================================================================================================================================================================================================================\n",
      "Total params: 18,360,453\n",
      "Trainable params: 18,360,453\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 74.11\n",
      "=================================================================================================================================================================================================================================\n",
      "Input size (MB): 25.17\n",
      "Forward/backward pass size (MB): 6739.20\n",
      "Params size (MB): 73.44\n",
      "Estimated Total Size (MB): 6837.81\n",
      "=================================================================================================================================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sega/progs/AI_Tasks/AIenv/lib/python3.10/site-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
      "/home/sega/progs/AI_Tasks/AIenv/lib/python3.10/site-packages/torch/storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return super().__sizeof__() + self.nbytes()\n"
     ]
    }
   ],
   "source": [
    "images, _ = next(iter(test_dataloader))\n",
    "TBwriter.add_graph(model, images)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "print(model_sum := torchinfo.summary(model, input_size=(BATCH_SIZE, 3, *CROP_SIZE), row_settings=[\"var_names\"], verbose=0, col_names=[\n",
    "      \"input_size\", \"output_size\", \"num_params\", \"params_percent\", \"kernel_size\", \"mult_adds\", \"trainable\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = smp.losses.DiceLoss(mode='binary')\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=0.0001)\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3, threshold=1e-3, cooldown=1, factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTuples(a1: tuple, a2: tuple):\n",
    "    for i in range(len(a1)):\n",
    "        a1[i] += a2[i]\n",
    "    return a1\n",
    "\n",
    "\n",
    "def train_step(net, criterion, optimizer, dataloader, epoch: int = None):\n",
    "    net.train()\n",
    "    running_loss = 0.\n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = net(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss\n",
    "\n",
    "    with torch.no_grad():\n",
    "        train_loss = running_loss / len(dataloader)\n",
    "    return train_loss.item()\n",
    "\n",
    "\n",
    "def valid_step(net, criterion, dataloader, epoch: int = None):\n",
    "    net.eval()\n",
    "    running_loss = 0.\n",
    "    IoU = metrics.BinaryJaccardIndex()\n",
    "    IoU.to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "\n",
    "            output = net(images)\n",
    "\n",
    "            IoU(output, labels)\n",
    "            loss = criterion(output, labels)\n",
    "            running_loss += loss\n",
    "\n",
    "        TBwriter.add_figure('valid_sample', create_image_plot(\n",
    "                origin=images[0].cpu().numpy().transpose(2, 1, 0),\n",
    "                true=colour_code_segmentation(reverse_one_hot(\n",
    "                    labels[0].cpu().numpy().transpose(2, 1, 0)), CLASS_RGB_VALUES),\n",
    "                pred=colour_code_segmentation(reverse_one_hot(\n",
    "                    output[0].cpu().numpy().transpose(2, 1, 0)), CLASS_RGB_VALUES)),\n",
    "                  epoch)\n",
    "\n",
    "        valid_loss = running_loss / len(valid_dataloader)\n",
    "\n",
    "        return valid_loss.item(), IoU.compute().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch = 32\n",
    "\n",
    "epoch = 0\n",
    " # epoch = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.state_dict(torch.load(\"checkpoint.pth\"))\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d71087aac64c47b87b7849b1c46e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]Saved weights with IoU: 0.45 | loss: 0.4245\n",
      "[5]Saved weights with IoU: 0.46 | loss: 0.4209\n",
      "[6]Saved weights with IoU: 0.46 | loss: 0.4161\n",
      "[7]Saved weights with IoU: 0.47 | loss: 0.4101\n",
      "[9]Saved weights with IoU: 0.51 | loss: 0.4012\n",
      "[10]Saved weights with IoU: 0.57 | loss: 0.3973\n",
      "[11]Saved weights with IoU: 0.57 | loss: 0.3934\n",
      "[12]Saved weights with IoU: 0.57 | loss: 0.3902\n",
      "[13]Saved weights with IoU: 0.58 | loss: 0.3879\n",
      "[14]Saved weights with IoU: 0.57 | loss: 0.3816\n",
      "[16]Saved weights with IoU: 0.58 | loss: 0.3800\n",
      "[17]Saved weights with IoU: 0.58 | loss: 0.3767\n",
      "[18]Saved weights with IoU: 0.58 | loss: 0.3742\n",
      "[19]Saved weights with IoU: 0.58 | loss: 0.3728\n",
      "[20]Saved weights with IoU: 0.58 | loss: 0.3705\n",
      "[21]Saved weights with IoU: 0.58 | loss: 0.3696\n",
      "[22]Saved weights with IoU: 0.58 | loss: 0.3667\n",
      "[23]Saved weights with IoU: 0.69 | loss: 0.3477\n",
      "[27]Saved weights with IoU: 0.72 | loss: 0.3451\n",
      "[29]Saved weights with IoU: 0.71 | loss: 0.3398\n",
      "[31]Saved weights with IoU: 0.72 | loss: 0.3387\n",
      "[33]Saved weights with IoU: 0.77 | loss: 0.3244\n",
      "[34]Saved weights with IoU: 0.78 | loss: 0.3182\n",
      "[36]Saved weights with IoU: 0.74 | loss: 0.3147\n",
      "[39]Saved weights with IoU: 0.79 | loss: 0.3130\n",
      "[40]Saved weights with IoU: 0.80 | loss: 0.3067\n",
      "[43]Saved weights with IoU: 0.79 | loss: 0.3063\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "best_loss = 10000\n",
    "trained = True\n",
    "\n",
    "pbar = tqdm(range(EPOCHS))\n",
    "pbar.update(epoch)\n",
    "while(epoch < EPOCHS):\n",
    "    train_loss = train_step(model, loss, optimizer, train_dataloader, epoch)\n",
    "    valid_loss, iou_score = valid_step(model, loss, valid_dataloader, epoch)\n",
    "    scheduler.step(valid_loss)\n",
    "\n",
    "    if WEIGHT_SAVER != \"nothing\" and valid_loss < best_loss and epoch > 3:\n",
    "        best_loss = valid_loss\n",
    "\n",
    "        print(f\"[{epoch}]Saved weights with IoU: {iou_score:.2f} | loss: {valid_loss:.4f}\")\n",
    "    \n",
    "        if WEIGHT_SAVER == \"all\":\n",
    "            torch.save(model.state_dict(),\n",
    "                       f\"weights_{epoch}.pth\")\n",
    "        elif WEIGHT_SAVER == \"last\":\n",
    "            torch.save(model.state_dict(),\n",
    "                       f\"weights_last.pth\")\n",
    "\n",
    "    TBwriter.add_scalar('valid loss', valid_loss, epoch)\n",
    "    TBwriter.add_scalar('train loss', train_loss, epoch)\n",
    "    \n",
    "    TBwriter.add_scalar('IoU', iou_score, epoch)\n",
    "\n",
    "    for i, param_group in enumerate(optimizer.param_groups):\n",
    "        TBwriter.add_scalar('learning rate', float(param_group['lr']), epoch)\n",
    "\n",
    "    epoch += 1\n",
    "    pbar.update()\n",
    "    pbar.set_description(\n",
    "        f'IoU: {iou_score:.2f}  | train/valid loss: {train_loss:.4f}/{valid_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TBwriter.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
