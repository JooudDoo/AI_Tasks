{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join as pjoin\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from additonFunc import create_image_plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "TBpath_orign_path = \"TB_cache/new/MyUnet_FixedSet_augmented_5\"\n",
    "TBpath = TBpath_orign_path + \"_valid_samples\"\n",
    "\n",
    "TBwriter = SummaryWriter(TBpath)\n",
    "\n",
    "target_dir = pjoin(TBpath_orign_path, 'valid_samples')\n",
    "\n",
    "folders = [pjoin(target_dir, filename) for filename in sorted(os.listdir(target_dir))]\n",
    "\n",
    "def extract_folder_id(folds):\n",
    "    max_id = -1\n",
    "    lastfld = None\n",
    "    for folder in folds:\n",
    "        id = int(folder.split('_')[-1])\n",
    "        if id > max_id:\n",
    "            lastfld = folder\n",
    "            max_id = id\n",
    "    return lastfld\n",
    "last_folder = extract_folder_id(folders)\n",
    "\n",
    "images = [pjoin(last_folder, filename) for filename in sorted(os.listdir(last_folder)) if \".png\" in filename]\n",
    "\n",
    "for ind, image_path in enumerate(images):\n",
    "    image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "    TBwriter.add_figure('valid_test', create_image_plot(valid_test=image), ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set dataset path\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "class CFG:\n",
    "    # ============== comp exp name =============\n",
    "    comp_name = 'vesuvius'\n",
    "\n",
    "    # comp_dir_path = './'\n",
    "    comp_dir_path = ''\n",
    "    comp_folder_name = ''\n",
    "    # comp_dataset_path = f'{comp_dir_path}datasets/{comp_folder_name}/'\n",
    "#     comp_dataset_path = f'{comp_dir_path}{comp_folder_name}/'\n",
    "    comp_dataset_path = ''\n",
    "    \n",
    "    exp_name = 'vesuvius_2d_slide_exp004'\n",
    "\n",
    "    # ============== pred target =============\n",
    "    target_size = 1\n",
    "\n",
    "    # ============== model cfg =============\n",
    "    model_name = 'FPN'\n",
    "    backbone = 'efficientnet-b3'\n",
    "    # backbone = 'se_resnext50_32x4d'\n",
    "\n",
    "    in_chans = 12 # 65\n",
    "    # ============== training cfg =============\n",
    "    size = 256\n",
    "    tile_size = 256\n",
    "    stride = tile_size // 2\n",
    "\n",
    "    train_batch_size = 32 # 32\n",
    "    valid_batch_size = train_batch_size * 2\n",
    "    use_amp = True\n",
    "\n",
    "    scheduler = 'GradualWarmupSchedulerV2'\n",
    "    # scheduler = 'CosineAnnealingLR'\n",
    "    epochs = 30 # 30\n",
    "\n",
    "    # adamW warmupあり\n",
    "    warmup_factor = 10\n",
    "    # lr = 1e-4 / warmup_factor\n",
    "    lr = 1e-4 / warmup_factor\n",
    "\n",
    "    # ============== fold =============\n",
    "    valid_id = 1\n",
    "\n",
    "    # objective_cv = 'binary'  # 'binary', 'multiclass', 'regression'\n",
    "    metric_direction = 'maximize'  # maximize, 'minimize'\n",
    "    # metrics = 'dice_coef'\n",
    "\n",
    "    # ============== fixed =============\n",
    "    pretrained = True\n",
    "    inf_weight = 'best'  # 'best'\n",
    "\n",
    "    min_lr = 1e-6\n",
    "    weight_decay = 1e-6\n",
    "    max_grad_norm = 1000\n",
    "\n",
    "    print_freq = 50\n",
    "    num_workers = 4\n",
    "\n",
    "    seed = 42\n",
    "\n",
    "    # ============== set dataset path =============\n",
    "    print('set dataset path')\n",
    "\n",
    "    outputs_path = f'outs'\n",
    "\n",
    "    submission_dir = outputs_path + 'submissions/'\n",
    "    submission_path = submission_dir + f'submission_{exp_name}.csv'\n",
    "\n",
    "    model_dir = outputs_path + \\\n",
    "        f'{comp_name}-models/'\n",
    "\n",
    "    figures_dir = outputs_path + 'figures/'\n",
    "\n",
    "    log_dir = outputs_path + 'logs/'\n",
    "    log_path = log_dir + f'{exp_name}.txt'\n",
    "\n",
    "    # ============== augmentation =============\n",
    "    train_aug_list = [\n",
    "        # A.RandomResizedCrop(\n",
    "        #     size, size, scale=(0.85, 1.0)),\n",
    "#         A.Resize(size, size),\n",
    "        A.RandomCrop(size, size),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "#         A.RandomBrightnessContrast(p=0.75),\n",
    "        A.ShiftScaleRotate(p=0.75),\n",
    "        A.OneOf([\n",
    "                A.GaussNoise(var_limit=[10, 50]),\n",
    "                A.GaussianBlur(),\n",
    "                A.MotionBlur(),\n",
    "                ], p=0.4),\n",
    "        A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n",
    "        A.CoarseDropout(max_holes=1, max_width=int(size * 0.3), max_height=int(size * 0.3), \n",
    "                        mask_fill_value=0, p=0.5),\n",
    "        # A.Cutout(max_h_size=int(size * 0.6),\n",
    "        #          max_w_size=int(size * 0.6), num_holes=1, p=1.0),\n",
    "        A.Normalize(\n",
    "            mean= [0] * in_chans,\n",
    "            std= [1] * in_chans\n",
    "        ),\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "\n",
    "    valid_aug_list = [\n",
    "        A.Resize(size, size),\n",
    "        A.Normalize(\n",
    "            mean= [0] * in_chans,\n",
    "            std= [1] * in_chans\n",
    "        ),\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "    \n",
    "    def __create_attr_info(self, atr_name):\n",
    "        atr_info = self.__getattribute__(atr_name)\n",
    "        try:\n",
    "            atr_info_str = str(atr_info)\n",
    "        except:\n",
    "            atr_info_str = \"NSC\"\n",
    "        return f\"{atr_name}: '{atr_info_str}'\"\n",
    "\n",
    "    def __str__(self):\n",
    "        result_string = \"\"\n",
    "        attrs_list = [attr for attr in dir(self) if not attr.startswith('__') and not attr.startswith(\"_CFG__\")]\n",
    "        for attr in attrs_list:\n",
    "            result_string += self.__create_attr_info(attr) + '\\n'\n",
    "        return result_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.CFG'>\n"
     ]
    }
   ],
   "source": [
    "print(str(CFG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
