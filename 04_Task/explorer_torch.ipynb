{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as Trans\n",
    "\n",
    "import torch.nn.init as init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Trans.ToTensor()\n",
    "\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='datasets',\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='datasets',\n",
    "    train=False,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(28*28, 100),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(100, 50),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.fcRes = nn.Sequential(\n",
    "            nn.Linear(50, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fcRes(x)\n",
    "        return x\n",
    "\n",
    "CELoss = nn.CrossEntropyLoss()\n",
    "net = MyNet()\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, optimizer, criterion):\n",
    "    running_loss = 0\n",
    "    for images, labels in train_dataloader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = net(images)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss\n",
    "    with torch.no_grad():\n",
    "        train_loss = running_loss / len(train_dataloader)\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def valid(net, criterion):\n",
    "    running_loss = 0\n",
    "    correct_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_dataloader:\n",
    "            output = net(images)\n",
    "\n",
    "            loss = criterion(output, labels)\n",
    "            running_loss += loss\n",
    "\n",
    "            pred = output.max(dim = 1, keepdim=True)[1]\n",
    "            correct_total += pred.eq(labels.view_as(pred)).sum()\n",
    "            \n",
    "        precison = correct_total / len(test_dataloader.dataset)\n",
    "        valid_loss = running_loss / len(test_dataloader)\n",
    "        return valid_loss, precison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be14cd40936c48f395b51dd7b24edc2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] train/valid loss: 0.7886/0.6037 prec: 0.7652\n",
      "[1] train/valid loss: 0.5756/0.5579 prec: 0.7778\n",
      "[2] train/valid loss: 0.5403/0.5426 prec: 0.7810\n",
      "[3] train/valid loss: 0.5208/0.5458 prec: 0.7806\n",
      "[4] train/valid loss: 0.5104/0.5438 prec: 0.7804\n",
      "[5] train/valid loss: 0.5004/0.5269 prec: 0.7843\n",
      "[6] train/valid loss: 0.4919/0.5349 prec: 0.7816\n",
      "[7] train/valid loss: 0.4873/0.5231 prec: 0.7863\n",
      "[8] train/valid loss: 0.4811/0.5487 prec: 0.7803\n",
      "[9] train/valid loss: 0.4784/0.5407 prec: 0.7822\n"
     ]
    }
   ],
   "source": [
    "for epoch in (pbar := tqdm(range(EPOCHS))):\n",
    "    train_loss = train(net, optimizer, CELoss)\n",
    "    valid_loss, prec = valid(net, CELoss)\n",
    "\n",
    "    print(f\"[{epoch}] train/valid loss: {train_loss:.4f}/{valid_loss:.4f} prec: {prec:.4f}\")\n",
    "    pbar.set_description(f\"train/valid loss: {train_loss:.4f}/{valid_loss:.4f} prec: {prec:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
